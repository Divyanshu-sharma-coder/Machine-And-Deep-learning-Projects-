{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNI3etUdGqvvmKrTEGmPQAi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# What is Handwritten Digit Recognition?\n","The handwritten digit recognition is the ability of computers to recognize human handwritten digits. It is a hard task for the machine because handwritten digits are not perfect and can be made with many different flavors. The handwritten digit recognition is the solution to this problem which uses the image of a digit and recognizes the digit present in the image."],"metadata":{"id":"SSzNnNK8uCmK"}},{"cell_type":"markdown","source":["#Prerequisites\n","The interesting Python project requires you to have basic knowledge of Python programming, deep learning with Keras library and the Tkinter library for building GUI.\n","\n","Install the necessary libraries for this project using this command:\n","\n","```bash\n","pip install numpy, tensorflow, keras, pillow\n","```\n","# The MNIST dataset\n","This is probably one of the most popular datasets among machine learning and deep learning enthusiasts. The MNIST dataset contains 60,000 training images of handwritten digits from zero to nine and 10,000 images for testing. So, the MNIST dataset has 10 different classes. The handwritten digits images are represented as a 28Ã—28 matrix where each cell contains grayscale pixel value."],"metadata":{"id":"Ttu1vgAAuM4m"}},{"cell_type":"markdown","source":["#Building Python Deep Learning Project on Handwritten Digit Recognition\n","Below are the steps to implement the handwritten digit recognition project:\n","\n","1. Import the libraries and load the dataset\n","First, we are going to import all the modules that we are going to need for training our model. The Keras library already contains some datasets and MNIST is one of them. So we can easily import the dataset and start working with it. The mnist.load_data() method returns us the training data, its labels and also the testing data and its labels."],"metadata":{"id":"vjWDuzGSumh7"}},{"cell_type":"code","source":["import keras\n","from keras.datasets import mnist\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Flatten\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras import backend as K\n","# the data, split between train and test sets\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","print(x_train.shape, y_train.shape)"],"metadata":{"id":"hbuGLwy0jTmR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 2. Preprocess the data\n","The image data cannot be fed directly into the model so we need to perform some operations and process the data to make it ready for our neural network. The dimension of the training data is (60000,28,28). The CNN model will require one more dimension so we reshape the matrix to shape (60000,28,28,1)."],"metadata":{"id":"TeU6uizsusBV"}},{"cell_type":"code","source":["\n","num_classes = 10\n","x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n","x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n","input_shape = (28, 28, 1)\n","# convert class vectors to binary class matrices\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","x_train /= 255\n","x_test /= 255\n","print('x_train shape:', x_train.shape)\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')"],"metadata":{"id":"nSWcnZfTjToj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764235047758,"user_tz":-330,"elapsed":56,"user":{"displayName":"Divyanshu Sharma","userId":"07945220963714254009"}},"outputId":"55971774-4f53-4761-e5d7-d0024f8945f5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["x_train shape: (60000, 28, 28, 1)\n","60000 train samples\n","10000 test samples\n"]}]},{"cell_type":"markdown","source":["#3. Create the model\n","Now we will create our CNN model in Python data science project. A CNN model generally consists of convolutional and pooling layers. It works better for data that are represented as grid structures, this is the reason why CNN works well for image classification problems. The dropout layer is used to deactivate some of the neurons and while training, it reduces offer fitting of the model. We will then compile the model with the Adadelta optimizer."],"metadata":{"id":"ipNXYWTEuwpg"}},{"cell_type":"code","source":["batch_size = 128\n","num_classes = 10\n","epochs = 10\n","model = Sequential()\n","model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=input_shape))\n","model.add(Conv2D(64, (3, 3), activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","model.add(Flatten())\n","model.add(Dense(256, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(num_classes, activation='softmax'))\n","model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adadelta(),metrics=['accuracy'])"],"metadata":{"id":"uYw6wkhjjT7g"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#4. Train the model\n","The model.fit() function of Keras will start the training of the model. It takes the training data, validation data, epochs, and batch size.\n","\n","It takes some time to train the model. After training, we save the weights and model definition in the â€˜mnist.h5â€™ file."],"metadata":{"id":"aruV4971u2JH"}},{"cell_type":"code","source":["hist = model.fit(x_train, y_train,batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(x_test, y_test))\n","print(\"The model has successfully trained\")\n","model.save('mnist.h5')\n","print(\"Saving the model as mnist.h5\")"],"metadata":{"id":"cugNfYexjT-X","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764236220508,"user_tz":-330,"elapsed":1172694,"user":{"displayName":"Divyanshu Sharma","userId":"07945220963714254009"}},"outputId":"8b213f7d-1010-4aaf-973b-97f76ef2bd34"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 226ms/step - accuracy: 0.1226 - loss: 2.2919 - val_accuracy: 0.3712 - val_loss: 2.2540\n","Epoch 2/10\n","\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 223ms/step - accuracy: 0.2378 - loss: 2.2481 - val_accuracy: 0.4802 - val_loss: 2.1946\n","Epoch 3/10\n","\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 224ms/step - accuracy: 0.3495 - loss: 2.1877 - val_accuracy: 0.5493 - val_loss: 2.1104\n","Epoch 4/10\n","\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 224ms/step - accuracy: 0.4375 - loss: 2.1029 - val_accuracy: 0.6273 - val_loss: 1.9877\n","Epoch 5/10\n","\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 228ms/step - accuracy: 0.5063 - loss: 1.9816 - val_accuracy: 0.6957 - val_loss: 1.8150\n","Epoch 6/10\n","\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 233ms/step - accuracy: 0.5742 - loss: 1.8140 - val_accuracy: 0.7490 - val_loss: 1.5924\n","Epoch 7/10\n","\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 229ms/step - accuracy: 0.6221 - loss: 1.6102 - val_accuracy: 0.7859 - val_loss: 1.3449\n","Epoch 8/10\n","\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 229ms/step - accuracy: 0.6651 - loss: 1.3916 - val_accuracy: 0.8088 - val_loss: 1.1131\n","Epoch 9/10\n","\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 227ms/step - accuracy: 0.6945 - loss: 1.2017 - val_accuracy: 0.8263 - val_loss: 0.9292\n","Epoch 10/10\n","\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 227ms/step - accuracy: 0.7124 - loss: 1.0559 - val_accuracy: 0.8362 - val_loss: 0.7958\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["The model has successfully trained\n","Saving the model as mnist.h5\n"]}]},{"cell_type":"markdown","source":["5. Evaluate the model\n","We have 10,000 images in our dataset which will be used to evaluate how good our model works. The testing data was not involved in the training of the data therefore, it is new data for our model. The MNIST dataset is well balanced so we can get around 99% accuracy."],"metadata":{"id":"EBPysLcXu7os"}},{"cell_type":"code","source":["score = model.evaluate(x_test, y_test, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])"],"metadata":{"id":"LsEffWXPjUN-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764236225723,"user_tz":-330,"elapsed":5163,"user":{"displayName":"Divyanshu Sharma","userId":"07945220963714254009"}},"outputId":"603dd828-d88a-49a0-d49f-688f04819204"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test loss: 0.7957794666290283\n","Test accuracy: 0.8361999988555908\n"]}]},{"cell_type":"markdown","source":["#6. Create GUI to predict digits For Computer\n","Now for the GUI, we have created a new file in which we build an interactive window to draw digits on canvas and with a button, we can recognize the digit. The Tkinter library comes in the Python standard library. We have created a function predict_digit() that takes the image as input and then uses the trained model to predict the digit.\n","\n","Then we create the App class which is responsible for building the GUI for our app. We create a canvas where we can draw by capturing the mouse event and with a button, we trigger the predict_digit() function and display the results.\n","\n","Hereâ€™s the full code for our gui_digit_recognizer.py file:"],"metadata":{"id":"oCFhVeEJu__1"}},{"cell_type":"code","source":["from keras.models import load_model\n","from tkinter import *\n","import tkinter as tk\n","import win32gui\n","from PIL import ImageGrab, Image\n","import numpy as np\n","model = load_model('mnist.h5')\n","def predict_digit(img):\n","    #resize image to 28x28 pixels\n","    img = img.resize((28,28))\n","    #convert rgb to grayscale\n","    img = img.convert('L')\n","    img = np.array(img)\n","    #reshaping to support our model input and normalizing\n","    img = img.reshape(1,28,28,1)\n","    img = img/255.0\n","    #predicting the class\n","    res = model.predict([img])[0]\n","    return np.argmax(res), max(res)\n","class App(tk.Tk):\n","    def __init__(self):\n","        tk.Tk.__init__(self)\n","        self.x = self.y = 0\n","        # Creating elements\n","        self.canvas = tk.Canvas(self, width=300, height=300, bg = \"white\", cursor=\"cross\")\n","        self.label = tk.Label(self, text=\"Thinking..\", font=(\"Helvetica\", 48))\n","        self.classify_btn = tk.Button(self, text = \"Recognise\", command =         self.classify_handwriting)\n","        self.button_clear = tk.Button(self, text = \"Clear\", command = self.clear_all)\n","        # Grid structure\n","        self.canvas.grid(row=0, column=0, pady=2, sticky=W, )\n","        self.label.grid(row=0, column=1,pady=2, padx=2)\n","        self.classify_btn.grid(row=1, column=1, pady=2, padx=2)\n","        self.button_clear.grid(row=1, column=0, pady=2)\n","        #self.canvas.bind(\"<Motion>\", self.start_pos)\n","        self.canvas.bind(\"<B1-Motion>\", self.draw_lines)\n","    def clear_all(self):\n","        self.canvas.delete(\"all\")\n","    def classify_handwriting(self):\n","        HWND = self.canvas.winfo_id() # get the handle of the canvas\n","        rect = win32gui.GetWindowRect(HWND) # get the coordinate of the canvas\n","        im = ImageGrab.grab(rect)\n","        digit, acc = predict_digit(im)\n","        self.label.configure(text= str(digit)+', '+ str(int(acc*100))+'%')\n","    def draw_lines(self, event):\n","        self.x = event.x\n","        self.y = event.y\n","        r=8\n","        self.canvas.create_oval(self.x-r, self.y-r, self.x + r, self.y + r, fill='black')\n","app = App()\n","mainloop()"],"metadata":{"id":"hjdOBhnOjUQi","colab":{"base_uri":"https://localhost:8080/","height":749},"executionInfo":{"status":"error","timestamp":1764236471874,"user_tz":-330,"elapsed":175,"user":{"displayName":"Divyanshu Sharma","userId":"07945220963714254009"}},"outputId":"656df651-c186-456a-bca1-107156bd884e"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'win32gui'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3467823730.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtkinter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtkinter\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mwin32gui\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageGrab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'win32gui'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"markdown","source":["#7. For Mobile Phones\n","\n","* But first install these Libraries\n","\n","```bash\n","!pip install --quiet gradio tensorflow pillow numpy"],"metadata":{"id":"Hn73BPgMvOOV"}},{"cell_type":"code","source":["# ===========================================\n","# ğŸ§  HANDWRITTEN DIGIT RECOGNIZER â€” Gradio 5.x compatible\n","# ===========================================\n","\n","!pip install --quiet gradio tensorflow pillow numpy\n","\n","from keras.models import load_model\n","import numpy as np\n","from PIL import Image, ImageOps\n","import gradio as gr\n","\n","# Load your pretrained model (ensure 'mnist.h5' is present)\n","model = load_model('mnist.h5')\n","\n","def predict_digit(editor_output):\n","    \"\"\"\n","    editor_output: dict from gr.ImageEditor â€” includes 'composite' image.\n","    \"\"\"\n","    if editor_output is None:\n","        return {}\n","\n","    # Extract the final drawn image\n","    img = editor_output.get(\"composite\")\n","    if img is None:\n","        return {}\n","\n","    # Convert to grayscale & preprocess\n","    img = Image.fromarray(img)\n","    img = ImageOps.grayscale(img)\n","    img = img.resize((28, 28))\n","    img_arr = np.array(img).reshape(1, 28, 28, 1) / 255.0\n","\n","    pred = model.predict(img_arr)[0]\n","    return {str(i): float(pred[i]) for i in range(10)}\n","\n","# Build Gradio Interface using ImageEditor for sketching\n","app = gr.Interface(\n","    fn = predict_digit,\n","    inputs = gr.ImageEditor(\n","        # default white canvas, brush = black â€” no args needed\n","    ),\n","    outputs = gr.Label(num_top_classes=3),\n","    title = \"ğŸ–Š MNIST Digit Recognizer\",\n","    description = \"Draw a digit (0â€“9) â€” the model will predict it.\"\n",")\n","\n","app.launch(debug=True)"],"metadata":{"id":"_0KbtTi3jU4m","colab":{"base_uri":"https://localhost:8080/","height":663},"outputId":"64f1bd04-fdd9-41af-f757-b21f4767cde3"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n","\n","Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n","* Running on public URL: https://4653832fedd936650b.gradio.live\n","\n","This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"]},{"data":{"text/html":["<div><iframe src=\"https://4653832fedd936650b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}]}]}